{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhSfbBviYpuf"
   },
   "source": [
    "# Assignment 3 ( Question 4) Know the hatred!\n",
    "\n",
    "## Instructions\n",
    "- Run this notebook on ```Google Colab(preferable)```\n",
    "- Write your code and analysis in the indicated cells.\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Do not attempt to change the contents of other cells. \n",
    "\n",
    "## Packages Used\n",
    "- all the packages that are imported in the template code\n",
    "\n",
    "## Submission\n",
    "- Rename the notebook to `<roll_number>_Assignment3_Q4.ipynb`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vr9cT4n04gsJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import sklearn\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8KX18mePvdv"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gqr3rUr4UNzh"
   },
   "source": [
    "#Dataset\n",
    "\n",
    "In the training data, the comments are labelled as one or more of the six categories; toxic, severe toxic, obscene, threat, insult and identity hate. This is essentially a multi-label classification problem.\n",
    "\n",
    "The dataset here is a multi-label classification dataset. To understand multi-label classification datasets, you can refer here: https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/ \n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "Here, we will be using Binary relevance to solve our multi-label classification problem\n",
    "\n",
    "\n",
    "\n",
    "**Binary Relevance**: This is probably the simplest which treats each label as a separate single classification problems. The key assumption here though, is that there are no correlation among the various labels.\n",
    "\n",
    "Finally, we will be summing up the accuracies obtained of all labels to obtain the final accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "Xsp3trnR8gLH",
    "outputId": "f24d3c75-a29a-4353-9635-b74a74b083c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-fd1b6ef0-4f96-4612-bd24-da7fb8293430\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117925</th>\n",
       "      <td>75ffa393bbc951bc</td>\n",
       "      <td>They are joined by a third accomplice.  If you...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144515</th>\n",
       "      <td>0e1bc17957e23750</td>\n",
       "      <td>\"\\n\\nOriginal Research\\nI removed the followin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29262</th>\n",
       "      <td>4d9377a34e6c0a16</td>\n",
       "      <td>I'll look around this week, I'm sure I can fin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159402</th>\n",
       "      <td>fd05dcd3dc62f50b</td>\n",
       "      <td>\"\\n\"\"Tidied up massively\"\" means I tidied it u...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110482</th>\n",
       "      <td>4f1bc9f5cbaa9d32</td>\n",
       "      <td>Grand Slam # \\n\\nI don't think the grand slam ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd1b6ef0-4f96-4612-bd24-da7fb8293430')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-fd1b6ef0-4f96-4612-bd24-da7fb8293430 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-fd1b6ef0-4f96-4612-bd24-da7fb8293430');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "117925  75ffa393bbc951bc  They are joined by a third accomplice.  If you...   \n",
       "144515  0e1bc17957e23750  \"\\n\\nOriginal Research\\nI removed the followin...   \n",
       "29262   4d9377a34e6c0a16  I'll look around this week, I'm sure I can fin...   \n",
       "159402  fd05dcd3dc62f50b  \"\\n\"\"Tidied up massively\"\" means I tidied it u...   \n",
       "110482  4f1bc9f5cbaa9d32  Grand Slam # \\n\\nI don't think the grand slam ...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "117925      0             0        0       0       0              0  \n",
       "144515      0             0        0       0       0              0  \n",
       "29262       0             0        0       0       0              0  \n",
       "159402      0             0        0       0       0              0  \n",
       "110482      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset\n",
    "\n",
    "train_df = pd.read_csv('q4_data/train.csv')\n",
    "test_df = pd.read_csv('q4_data/test.csv')\n",
    "\n",
    "#dataset understanding\n",
    "train_df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Di6n18tL7kc2",
    "outputId": "959d21f1-2f17-4a89-acae-662c1997d2f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in test is 153164\n",
      "Total rows in train is 159571\n",
      "obscene           8449\n",
      "insult            7877\n",
      "toxic            15294\n",
      "severe_toxic      1595\n",
      "identity_hate     1405\n",
      "threat             478\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# let's see the total rows in train, test data and the numbers for the various categories\n",
    "print('Total rows in test is {}'.format(len(test_df)))\n",
    "print('Total rows in train is {}'.format(len(train_df)))\n",
    "print(train_df[cols_target].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ciejlBb074r3"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bknzbJYX8CEN"
   },
   "outputs": [],
   "source": [
    "train_df['comment_text'] = train_df['comment_text'].map(lambda com : clean_text(com))\n",
    "test_df['comment_text'] = test_df['comment_text'].map(lambda com : clean_text(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ozooblAOQBG"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop('char_length',axis=1)\n",
    "X = train_df.comment_text\n",
    "test_X = test_df.comment_text\n",
    "print(X.shape, test_X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEPiqW7nOeZM"
   },
   "source": [
    "Now, we will be experimenting this classification problem with different classifiers. We will be using pre-trained models inorder to obtain the required embeddings. Here, we will be using BERT and Universal Sentence Encoder embeddings.\n",
    "\n",
    "\n",
    "Understand how Elmo and USE(Universal Sentence Encoder) works here. You can use any of both to train your classifiers.\n",
    "\n",
    "To understand how different sentence embeddings work, you can refer to this link: https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial \n",
    "\n",
    "Please give it a look before you start working with transfer learning/ sentence embeddings like BERT, Elmo, Ulm-fit, USE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6KUcPjMypJm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzqSibiizNG8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWL8KlxrzNDk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_YhipFSzNaC"
   },
   "outputs": [],
   "source": [
    "#loading universal sentence encoder\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "# Load pre-trained universal sentence encoder model\n",
    "use_embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "elmo_embed = hub.Module(\"https://tfhub.dev/google/elmo/3\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LoX3HCa94G7"
   },
   "outputs": [],
   "source": [
    "def get_use_embedding(sentence):\n",
    "  embedding = use_embed([sentence])\n",
    "  embedding = embedding.numpy()\n",
    "  return embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCTw6H_sPg_m"
   },
   "outputs": [],
   "source": [
    "#to obtain bert embeddings ( you need not completely understand how it works)\n",
    "#you can directly use the function get_bert_embedding to obtain the embedding\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "\n",
    "\n",
    "def get_bert_embedding(sentence):\n",
    "  encoded_input = tokenizer(sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "  with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "  sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "  return sentence_embedding[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3eafXPxQYp4"
   },
   "outputs": [],
   "source": [
    "#Obtain X_test and X_train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BY4InEH5__Ea"
   },
   "source": [
    "# Classifiers\n",
    "Here, we use different classifiers for our classification problem. You can directly import classifiers for first two.\n",
    "\n",
    "\n",
    "*   Naive Bayes classifier\n",
    "*   Support Vector Machine\n",
    "*   Multi-layer Perceptron(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G06b8xt7CIra"
   },
   "outputs": [],
   "source": [
    "#calculate the accuracies obtained, u can use sklearn metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bS2_lOBIzM8u"
   },
   "outputs": [],
   "source": [
    "# Naive Bayes classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJ_02S_RzM6f"
   },
   "outputs": [],
   "source": [
    "#Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHOBzVA7Cg35"
   },
   "source": [
    "Which classifier of the three performed better, and why do you think so ?\n",
    "\n",
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwsWLvpyCqya"
   },
   "source": [
    "#Multi-layer Perceptron\n",
    "\n",
    "For Multi-layer Perceptron, first you will be implementing your own articial Neural network, and then compare it with sklearn's MLP layer.\n",
    "\n",
    "\n",
    "Implement your own artificial Neural Network (MLP)\n",
    "Few Steps to be followed(for your reference):\n",
    "\n",
    "*   Initialise the weights randomly\n",
    "*   Decide upon the number of layers you wanna have and number of neurons associated in each layer. ( Have a clear idea of what will be the size of the weight matrices).\n",
    "*   Write the code for forward and backward propogations\n",
    "*   Decide upon the loss function\n",
    "*   Train the model\n",
    "*   Predict the labels after training the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qudVxLAjzM19"
   },
   "outputs": [],
   "source": [
    "# you can remove returns statements if u think they are not required\n",
    "# you can also add functions if needed\n",
    "\n",
    "def initialise_weights():\n",
    "  return\n",
    "  \n",
    "\n",
    "def loss_function():\n",
    "  return \n",
    "\n",
    "\n",
    "def forward_layer():\n",
    "  return \n",
    "\n",
    "\n",
    "def backward_propogation():\n",
    "  return \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5kgWuGazMzc"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuHKjRN4Hqc7"
   },
   "outputs": [],
   "source": [
    "#report accuracies\n",
    "#here, you need to predict for each of the label as we have trained classifiers in such a way\n",
    "\n",
    "def predict():\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LedEtOXvH8IP"
   },
   "outputs": [],
   "source": [
    "#report accuracies on the test dataset \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9BxRHWEH7CE"
   },
   "source": [
    "Now, compare your implemented MLP with the sklearn MLP layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-FZgOy8IL4z"
   },
   "outputs": [],
   "source": [
    "#report accuracies both on train dataset and test dataset\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVJdZaYCPYQK"
   },
   "source": [
    "Which MLP performed better? \n",
    "Understand and Analyse."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Know the hatred!.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
